{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DKTC 최종 모델 학습 및 제출 파일 생성 (개선된 데이터 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 전체 데이터로 모델 재학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mecab_ko import Tagger\n",
    "import numpy as np\n",
    "\n",
    "print(\"데이터 로딩 중...\")\n",
    "# 데이터 로드 (v2 일반 대화 사용)\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "general_df_v2 = pd.read_csv('data/train_general_conversation_v2.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# 전체 학습 데이터 합치기\n",
    "df_full_train = pd.concat([train_df, general_df_v2], ignore_index=True)\n",
    "\n",
    "# README에 명시된 클래스 번호에 맞게 직접 매핑\n",
    "class_mapping = {\n",
    "    '협박 대화': 0,\n",
    "    '갈취 대화': 1,\n",
    "    '직장 내 괴롭힘 대화': 2,\n",
    "    '기타 괴롭힘 대화': 3,\n",
    "    '일반 대화': 4\n",
    "}\n",
    "df_full_train['class'] = df_full_train['class'].map(class_mapping)\n",
    "\n",
    "print(f\"전체 학습 데이터 크기: {len(df_full_train)}\")\n",
    "print(\"데이터 준비 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer 정의\n",
    "mecab_tagger = Tagger()\n",
    "def mecab_tokenizer(text):\n",
    "    parsed = mecab_tagger.parse(text)\n",
    "    return [line.split('\t')[0] for line in parsed.split('\n') if '\t' in line]\n",
    "\n",
    "# TF-IDF 벡터화 (1,3-gram)\n",
    "print(\"TF-IDF 벡터화 진행 중...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=mecab_tokenizer, ngram_range=(1, 3), min_df=3, max_df=0.9)\n",
    "\n",
    "# 전체 학습 데이터로 TF-IDF 학습 및 변환\n",
    "X_full_train_tfidf = tfidf_vectorizer.fit_transform(df_full_train['conversation'])\n",
    "\n",
    "# 테스트 데이터 변환\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['text'])\n",
    "\n",
    "print(f\"벡터화 완료! Vocabulary size: {len(tfidf_vectorizer.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀 모델 학습\n",
    "print(\"최종 모델 학습 중...\")\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_full_train_tfidf, df_full_train['class'])\n",
    "print(\"모델 학습 완료!\")\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "print(\"테스트 데이터 예측 중...\")\n",
    "test_predictions = lr_model.predict(X_test_tfidf)\n",
    "print(\"예측 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 최종 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출용 데이터프레임 생성\n",
    "submission_final = pd.DataFrame()\n",
    "submission_final['idx'] = test_df['idx']\n",
    "submission_final['class'] = test_predictions\n",
    "\n",
    "# 결과 확인\n",
    "display(submission_final.head())\n",
    "\n",
    "# 파일로 저장\n",
    "submission_final.to_csv('submission_final_v2.csv', index=False)\n",
    "\n",
    "print(\"submission_final_v2.csv 파일이 성공적으로 생성되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
